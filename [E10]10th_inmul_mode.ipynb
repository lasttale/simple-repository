{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verbal-memory",
   "metadata": {},
   "source": [
    "# 10 인물 모드 문제점 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-marker",
   "metadata": {},
   "source": [
    "## 10.1 인물모드 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-tension",
   "metadata": {},
   "source": [
    "### 10.1.1 사람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요모듈 import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 가져오기\n",
    "import os\n",
    "img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/이주빈.jpeg' \n",
    "img_orig = cv2.imread(img_path) \n",
    "print (img_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class 생성\n",
    "class DeepLabModel(object):\n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "    # __init__()에서 모델 구조를 직접 구현하는 대신, tar file에서 읽어들인 그래프구조 graph_def를 \n",
    "    # tf.compat.v1.import_graph_def를 통해 불러들여 활용하게 됩니다. \n",
    "    def __init__(self, tarball_path):\n",
    "        self.graph = tf.Graph()\n",
    "        graph_def = None\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.compat.v1.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "        tar_file.close()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "    # 이미지를 전처리하여 Tensorflow 입력으로 사용 가능한 shape의 Numpy Array로 변환합니다.\n",
    "    def preprocess(self, img_orig):\n",
    "        height, width = img_orig.shape[:2]\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = cv2.resize(img_orig, target_size)\n",
    "        resized_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        img_input = resized_rgb\n",
    "        return img_input\n",
    "        \n",
    "    def run(self, image):\n",
    "        img_input = self.preprocess(image)\n",
    "\n",
    "        # Tensorflow V1에서는 model(input) 방식이 아니라 sess.run(feed_dict={input...}) 방식을 활용합니다.\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [img_input]})\n",
    "\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return cv2.cvtColor(img_input, cv2.COLOR_RGB2BGR), seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 불러오기\n",
    "# define model and download & load pretrained weight\n",
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "\n",
    "model_dir = os.getenv('HOME')+'/aiffel/human_segmentation/models'\n",
    "tf.io.gfile.makedirs(model_dir)\n",
    "\n",
    "print ('temp directory:', model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, 'deeplab_model.tar.gz')\n",
    "if not os.path.exists(download_path):\n",
    "    urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + 'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "                   download_path)\n",
    "\n",
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#네트워크에 이미지 입력\n",
    "img_resized, seg_map = MODEL.run(img_orig)\n",
    "print (img_orig.shape, img_resized.shape, seg_map.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-moldova",
   "metadata": {},
   "source": [
    "15 사람 잘 나왔음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 라벨 의미\n",
    "LABEL_NAMES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "]\n",
    "len(LABEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사람만 검출\n",
    "img_show = img_resized.copy()\n",
    "seg_map = np.where(seg_map == 15, 15, 0) # 예측 중 사람만 추출\n",
    "img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
    "img_mask = img_mask.astype(np.uint8)\n",
    "color_mask = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "img_show = cv2.addWeighted(img_show, 0.6, color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 크기 복원\n",
    "img_mask_up = cv2.resize(img_mask, img_orig.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "_, img_mask_up = cv2.threshold(img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.imshow(img_mask_up, cmap=plt.cm.binary_r)\n",
    "ax.set_title('Original Size Mask')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.imshow(img_mask, cmap=plt.cm.binary_r)\n",
    "ax.set_title('DeepLab Model Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경만 추출\n",
    "img_mask_color = cv2.cvtColor(img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "img_bg_mask = cv2.bitwise_not(img_mask_color)\n",
    "img_bg = cv2.bitwise_and(img_orig, img_bg_mask)\n",
    "plt.imshow(img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 블러처리\n",
    "img_bg_blur = cv2.blur(img_bg, (13,13))#13은 블러 정도\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사람과 배경 합치기\n",
    "img_concat = np.where(img_mask_color==255, img_orig, img_bg_blur)\n",
    "plt.imshow(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-sherman",
   "metadata": {},
   "source": [
    "### 10.1.2  고양이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 가져오기\n",
    "import os\n",
    "img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/고양이.jpg' \n",
    "img_orig = cv2.imread(img_path) \n",
    "print (img_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#네트워크에 이미지 입력\n",
    "img_resized, seg_map = MODEL.run(img_orig)\n",
    "print (img_orig.shape, img_resized.shape, seg_map.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-bulgarian",
   "metadata": {},
   "source": [
    "8 고양이 잘나왔음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#고양이만 검출\n",
    "img_show = img_resized.copy()\n",
    "seg_map = np.where(seg_map == 8, 8, 0) # 예측 중 고양이만 추출\n",
    "img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
    "img_mask = img_mask.astype(np.uint8)\n",
    "color_mask = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "img_show = cv2.addWeighted(img_show, 0.6, color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 크기 복원\n",
    "img_mask_up = cv2.resize(img_mask, img_orig.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "_, img_mask_up = cv2.threshold(img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.imshow(img_mask_up, cmap=plt.cm.binary_r)\n",
    "ax.set_title('Original Size Mask')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.imshow(img_mask, cmap=plt.cm.binary_r)\n",
    "ax.set_title('DeepLab Model Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경만 추출\n",
    "img_mask_color = cv2.cvtColor(img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "img_bg_mask = cv2.bitwise_not(img_mask_color)\n",
    "img_bg = cv2.bitwise_and(img_orig, img_bg_mask)\n",
    "plt.imshow(img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-roots",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#이미지 블러처리\n",
    "img_bg_blur = cv2.blur(img_bg, (20,20))#13은 블러 정도\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사람과 배경 합치기\n",
    "img_concat = np.where(img_mask_color==255, img_orig, img_bg_blur)\n",
    "plt.imshow(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-republic",
   "metadata": {},
   "source": [
    "### 10.1.3 크로마키"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 가져오기\n",
    "import os\n",
    "img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/이주빈2.jpg' \n",
    "img_orig = cv2.imread(img_path) \n",
    "print (img_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#네트워크에 이미지 입력\n",
    "img_resized, seg_map = MODEL.run(img_orig)\n",
    "print (img_orig.shape, img_resized.shape, seg_map.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-clothing",
   "metadata": {},
   "source": [
    "15 사람 잘나왔음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사람만 검출\n",
    "img_show = img_resized.copy()\n",
    "seg_map = np.where(seg_map == 15, 15, 0) # 예측 중 사람만 추출\n",
    "img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
    "img_mask = img_mask.astype(np.uint8)\n",
    "color_mask = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "img_show = cv2.addWeighted(img_show, 0.6, color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 크기 복원\n",
    "img_mask_up = cv2.resize(img_mask, img_orig.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "_, img_mask_up = cv2.threshold(img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.imshow(img_mask_up, cmap=plt.cm.binary_r)\n",
    "ax.set_title('Original Size Mask')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.imshow(img_mask, cmap=plt.cm.binary_r)\n",
    "ax.set_title('DeepLab Model Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경만 추출\n",
    "img_mask_color = cv2.cvtColor(img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "img_bg_mask = cv2.bitwise_not(img_mask_color)\n",
    "img_bg = cv2.bitwise_and(img_orig, img_bg_mask)\n",
    "plt.imshow(img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "#변경할 이미지 resize\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('data/src/sample.png')\n",
    "\n",
    "img_resize = img.resize((int(img.width / 2), int(img.height / 2)))\n",
    "img_resize_lanczos.save('data/dst/sample_pillow_resize_half.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경이미지 가져오기\n",
    "import os\n",
    "img_path_bag = os.getenv('HOME')+'/aiffel/human_segmentation/images/사무실.jpg' \n",
    "img_orig_bag = cv2.imread(img_path_bag) \n",
    "print (img_orig_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경이미지 가져오기\n",
    "from PIL import Image\n",
    "import os\n",
    "img_path_bag = os.getenv('HOME')+'/aiffel/human_segmentation/images/사무실.jpg' \n",
    "img = Image.open(img_path_bag)\n",
    "\n",
    "img_resize = img.resize((int(img_orig.width), int(img_orig.height)))\n",
    "img_resize_lanczos.save(img_path_bag)\n",
    "\n",
    "img_orig_bag = cv2.imread(img_resize) \n",
    "print (img_orig_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경이미지 resize\n",
    "#from PIL import Image\n",
    "\n",
    "#img_resized_bag, seg_map_bag = MODEL.run(img_orig_bag)\n",
    "#img_resized_bag = img_orig_bag.resize((int(img_orig.width), int(img_orig.height)))\n",
    "#print (img_orig_bag.shape, img_resized_bag.shape, seg_map_bag.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-ticket",
   "metadata": {},
   "source": [
    "20 tv? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경이미지 교체\n",
    "#img_bg_change = cv2.blur(img_bg, (20,20))#13은 블러 정도\n",
    "plt.imshow(cv2.cvtColor(img_orig_bag, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사람과 배경 합치기\n",
    "img_concat = np.where(img_mask_color==255, img_orig, img_orig_bag)\n",
    "plt.imshow(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배경설정\n",
    "#img_show_bag = img_resized_bag.copy()\n",
    "#seg_map_bag = np.where(seg_map_bag == 0, 0, 0) # 배경\n",
    "#img_mask_bag = seg_map_bag * (255/seg_map_bag.max()) # 255 normalization\n",
    "#img_mask_bag = img_mask_bag.astype(np.uint8)\n",
    "#color_mask_bag = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "#img_show_bag = cv2.addWeighted(img_show_bag, 0.6, color_mask_bag, 0.35, 0.0)\n",
    "\n",
    "#plt.imshow_bag(cv2.cvtColor(img_show_bag, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite('my_image_2.png', img_show )  수정된 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-twins",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
